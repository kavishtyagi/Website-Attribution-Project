---
title: "Untitled"
author: "Kavish Tyagi"
date: "January 31, 2019"
output: word_document
---



```{r}
## XGBoost Test Model without stop words

library(lime)
library(xgboost) # the classifier
library(text2vec) # used to build the BoW matrix
library(plyr)
library(magrittr)
library(lattice)
library(ggplot2)
library(caret)
library(stopwords)
library(tm)
```



##Read the data set and split in 75-25 train test split
```{r}
df = read.csv("Political Articles.csv.txt")
smp_size <- floor(0.75 * nrow(df))
df_attempt1 = df[c(6,2)] # subsetting the data set by selecting "Post.Text" and "Blog.ID"


```

## set the seed to make your partition reproducible
```{r}
set.seed(321)
train_ind <- sample(seq_len(nrow(df_attempt1)), size = smp_size)
```

## Creating another colunms to make Blog ID as factor of level 1-10
```{r}
df_attempt1$Blog.ID_lab = factor(df_attempt1$Blog.ID, 
                                 levels = c(unique(df_attempt1$Blog.ID)),
                                 labels = c(0,1,2,3,4,5,6,7,8,9))
```


##Removing stop words
```{r}
en_stop = stopwords("en")
common_stop = c("The")
df_attempt1$Post.Text_nrm = tolower(df_attempt1$Post.Text)
df_attempt1$Post.Text_nrm = removeWords(as.character(df_attempt1$Post.Text_nrm),en_stop)
df_attempt1$Post.Text_nrm = removeWords(as.character(df_attempt1$Post.Text_nrm),common_stop)

```

##Creating Train and Test data set
```{r}
train <- df_attempt1[train_ind, ]#Training data set 
test <- df_attempt1[-train_ind, ]#Test data set
```

##Labels subsetted to another data frame
```{r}
train_labs <- as.numeric(train$Blog.ID_lab) - 1 
test_labs <- as.numeric(test$Blog.ID_lab) - 1 
```



## Tokenizing of text data
```{r}
get_matrix = function(Post.Text_nrm) {
  it <- itoken(Post.Text_nrm, progressbar = FALSE)
  create_dtm(it, vectorizer = hash_vectorizer())
}
dtm_test = get_matrix(as.character(test$Post.Text_nrm))
dtm_train = get_matrix(as.character(train$Post.Text_nrm))
```




## XGB model for BlogID - 1001
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1001")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1001"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1001"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```






## XGB model for BlogID - 1002
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1002")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1002"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1002"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1003
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1003")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1003"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1003"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1004
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1004")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1004"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1004"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```


## XGB model for BlogID - 1005
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1005")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1005"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1005"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1006
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1006")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1006"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1006"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```




## XGB model for BlogID - 1007
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1007")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1007"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1007"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1008
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1008")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1008"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1008"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1009
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1009")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1009"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1009"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```



## XGB model for BlogID - 1010
```{r}
param <- list(max_depth = 7, 
              eta = 0.1, 
              objective = "binary:logistic", 
              eval_metric = "error", 
              nthread = 1)
xgb_model <- xgb.train(param, 
                       xgb.DMatrix(dtm_train, label = (train$Blog.ID == "1010")),
                       nrounds = 50)
```


# We use a (standard) threshold of 0.5
```{r}
predictions <- predict(xgb_model, dtm_test) > 0.5
test_labels <- test$Blog.ID == "1010"

print(test_labels)
```

# Accuracy

```{r}
print(mean(predictions == test_labels))
```

# We select sentences from the label Blog.ID - "1010"
```{r}
sentence_to_explain <- head(test[test_labels,]$Post.Text_nrm,5)
explainer <- lime(sentence_to_explain, model = xgb_model, 
                  preprocess = get_matrix)
explanation <- explain(sentence_to_explain, explainer, n_labels = 1, 
                       n_features = 5)
```

# Another more graphical view of the same information (2 first sentences only)

```{r fig.height=10, fig.width=10}
plot_features(explanation)
```
```{r echo=TRUE, fig.height=10, fig.width=10}
plot_text_explanations(explanation)
```


